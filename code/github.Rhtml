BCMC-code

<body>
//1. Assume the parameters of survival function and true value//
/// 1.1 set observation intervals
k<-260
interval<-1
a<- seq(0,interval*k,interval)
/// 1.2.set transition roads
m<-4
s<-c(1:m)
#s<-1#PFS_PD
#s<-2#PD_PFS
#s<-3#PFS_D
#s<-4#PD_D

/// 1.3.Assume the baseline survival function parameters: lamda, alpha for the transition  
lamda_pfs<-0.2
alpha_pfs<-1.2
lamda_pd<-0.2
alpha_pd<-0.9
s_pfs<-exp(-lamda_pfs*((a/10)^alpha_pfs))
s_pd<-exp(-lamda_pd*((a/10)^alpha_pd))

/// 1.4.Assume beta
X<-1#The value of the covav riate, 1 represents the intervention
beta<- matrix(0, nrow=m, ncol=k)
#1. Constant
for(t in 1:k){
  beta[1,t]<-(-log(2))
  beta[2,t]<-log(2)
  beta[3,t]<-(-log(2))
  beta[4,t]<-(-log(2))
}

write.csv(beta[,1:(k)],"~/Desktop/beta_true_con.csv")


#2. Monotonic
beta<- matrix(0, nrow=m, ncol=k)
for(t in 1:k){
  beta[1,t]<-(-3.5)+log(t/20+15)#
  beta[2,t]<-4-log(t/10+25)
  beta[3,t]<-(-3.5)+log(t/20+15)
  beta[4,t]<-(-3.5)+log(t/20+15)
}

write.csv(beta,"~/Desktop/beta_true_var.csv")


#3.U-shaped 
beta<- matrix(0, nrow=m, ncol=k)
  for(t in 1:k){
    x<-t
  si<-60
  mu<-130
  beta[1,t]<-(-1)*40*si^(-1)*exp((-(x-130)^2)/(2*si^2))#
  beta[2,t]<-45*si^(-1)*exp((-(x-130)^2)/(2*si^2))
  beta[3,t]<-(-1)*40*si^(-1)*exp((-(x-130)^2)/(2*si^2))#
  beta[4,t]<-(-1)*40*si^(-1)*exp((-(x-130)^2)/(2*si^2))#
  }
 write.csv(beta,"~/Desktop/beta_true_norm.csv")


HR<- matrix(0, nrow=m, ncol=k)
HR<-exp(beta)

plot(1:k, HR[1,][1:k], type="l", col="green3", ylim=c(0,3), xlab="Time", ylab="HR", main="Dynamic HR (True value)",bty ="l",lwd=2)
lines(1:k, HR[2,][1:k], type="l", col="orange",lwd=2)
lines(1:k, rep(1,k)[1:k], lty=2, col="red",lwd=2)
legend("topright", legend=c("Other paths", "PD-PFS","HR=1"), col=c("green3", "orange", "red"), bty ="n",lty=1, ,lwd=2,cex=0.8)

#Definite test group
s_pfs_tr<-c(s_pfs[1],s_pfs[-1]^(exp(X*beta[1,])))
s_pd_tr<-c(s_pd[1],s_pd[-1]^(exp(X*beta[2,])))
~~~~~~~~~





// 2. Generate the transition probability matrix
library(expm)
library(pracma)
/// 2.1 generate transition probability matrixs of k periods

# control group
p_list <- c(rep(NA, 3*3*k))
dim(p_list)<-c(3,3,k)
for (t in 1:k) {
  p <- matrix(0, nrow = 3, ncol = 3)  
  col_names <-c("PFS","PD","D")
  row_names <- c("PFS","PD","D")
  p[1,1]<-s_pfs[t+1]/s_pfs[t]
  p[1,3]<-0.001
  p[1,2]<-max((1-p[1,1]-p[1,3]),0)
  p[2,2]<-s_pd[t+1]/s_pd[t]
  p[2,3]<-0.002
  p[2,1]<-max((1-p[2,2]-p[2,3]),0)
  p[3,1]<-0
  p[3,2]<-0
  p[3,3]<-1
  p_list[,,t] <- p  
}

plot(1:k, p_list[1,2,1:k], type="l", col="steelblue2", ylim=c(0,0.08), xlab="Time", ylab="P", main="Probability",bty ="l",lwd=2)
lines(1:k, p_list[2,1,1:k], type="l", col="purple",lwd=2)
lines(1:k, p_list[1,3,1:k], type="l", col="palegreen3",lwd=2)
lines(1:k, p_list[2,3,1:k], type="l", col="gold1",lwd=2)
legend("topright", legend=c("PFS-PD", "PD-PFS","PFS-D","PD-D"), col=c("steelblue2", "purple", "palegreen3", "gold1"), lty=1, ,lwd=2,cex=0.8, bty = "n")

# simulated the period of 1-8 weeks, 56 points were inserted
e<-7
int<-c((1:56)/7,9:k)
K<-length(int)

library(pracma)
p_list_ste<- c(rep(0, 3*3*K))
dim(p_list_ste)<-c(3,3,K)
for(i in 1:8){
  p_list_ste[,,((i-1)*7+1):((i-1)*7+7)]<-abs(sqrtm(sqrtm(sqrtm(p_list[,,1])$B)$B)$B)
}
p_list_ste[,,57:K]<-p_list[,,9:k]

#treatment group
X<-1
p_list_tr <- c(rep(0, 3*3*(k)))
dim(p_list_tr)<-c(3,3,(k))
for (t in 1:(k)) {
  p <- matrix(0, nrow = 3, ncol = 3)  
  col_names <-c("PFS","PD","D")
  row_names <- c("PFS","PD","D")
  p[1,3]<-0.001*(exp(X*beta[3,t]))
  p[1,1]<-s_pfs_tr[t+1]/s_pfs_tr[t]#alpha=1，=exp(-lamda)
  p[1,2]<-max(1-p[1,1]-p[1,3],0)
  p[2,3]<-0.002*(exp(X*beta[4,t]))
  p[2,2]<-s_pd_tr[t+1]/s_pd_tr[t]
  p[2,1]<-max((1-p[2,2]-p[2,3]),0)
  p[3,1]<-0
  p[3,2]<-0
  p[3,3]<-1
  p_list_tr[,,t] <- p 
}

plot(1:(k), p_list_tr[1,2,1:(k)], type="l", col="steelblue2", ylim=c(0,0.08), xlab="Time", ylab="P", main="Probability",bty ="l",lwd=2)
lines(1:(k), p_list_tr[2,1,1:(k)], type="l", col="purple",lwd=2)
lines(1:(k), p_list_tr[1,3,1:(k)], type="l", col="palegreen3",lwd=2)
lines(1:(k), p_list_tr[2,3,1:(k)], type="l", col="gold1",lwd=2)
legend("topright", legend=c("PFS-PD", "PD-PFS","PFS-D","PD-D"), col=c("steelblue2", "purple", "palegreen3", "gold1"), lty=1,lwd=2, cex=0.8, bty = "n")

# simulated the period of 1-8 weeks, 56 points were inserted
e<-7
int<-c((1:56)/8,9:(k))

p_list_tr_ste<- c(rep(0, 3*3*K))
dim(p_list_tr_ste)<-c(3,3,K)
for(i in 1:8){
  p_list_tr_ste[,,((i-1)*7+1):((i-1)*7+7)]<-abs(sqrtm(sqrtm(sqrtm(p_list_tr[,,i])$B)$B)$B)
}
p_list_tr_ste[,,57:K]<-p_list_tr[,,9:(k)]
~~~~~~~~~



// 3.Simulate the state transition 

library(foreach)
library(iterators)
library(parallel)
library(doParallel)

/// 3.1. Repeat the cycle to generate sample data _ treatment group
states<- 3  # number of states
n<-100 # The number of samples n<-5000
k<-260# the number of loops
data_tran<-list()
n.cores <- detectCores()
n.cores
cl <- makeCluster(n.cores-1) 
registerDoParallel(cl)
for(kk in 1:K){
      p_k<- p_list_ste
     p_k[,,(kk:K)]<- p_list_tr_ste[,,(kk:K)]
data<- as.data.frame(NA, nrow = n, ncol = K+1)
data<- foreach(i = 1:n,
               .combine = rbind,
               .errorhandling = "pass") %dopar% {
  current_state <- ifelse(i<=(n/2),1,2)
  da<-c(current_state)
  # Store sample sequences
  for(t in 1:K){
    next_state <- sample(1:states, 1, prob = p_k[current_state,,t])
  da<- c(da,next_state)
  current_state<-next_state
  }
  return(da)
               }
 data_tran[[kk]]<-data  
}


/// 3.2. Repeat the cycle to generate sample data _ control group
p_k<-p_list_ste
data<-foreach(i = 1:n,
               .combine = rbind,
               .errorhandling = "pass") %dopar% {
  current_state <- ifelse(i<=(n/2),1,2)
  da<-c(current_state)
  # Store sample sequences
  for(t in 1:length(int)){
    next_state <- sample(1:states, 1, prob = p_list_tr_ste[current_state,,t])
  da<- c(da,next_state)
  current_state<-next_state
  }
  return(da)
               }
data_tran[[K+1]]<-data
stopCluster(cl)
write.csv(data_tran,"~/Desktop/data_tran_con.csv")#_con,_var,_norm
~~~~~~~~~




// 4. Extracted  survival time data

cl <- makeCluster(8-1) 
registerDoParallel(cl)
C<-list()
for(kk in 1:(K+1)){#(K+1)
  x<-ifelse(kk<=K,1,0)
data<-data_tran[[kk]]
c_1<-foreach(i = 1:n,
               .combine = rbind,
             .packages = c("dplyr"),
               .errorhandling = "pass") %dopar% {
                 c<-c(rep(0, 6))
                 Time<-c(rep(1, K))
                 s<-c(rep(0, K))
  d<-data[i,]
  sit<-min(which(is.na(d)==FALSE))#if have NA
for(t in sit:(K-1)){

  #survival time t
  Time[t+1]<-ifelse(d[t]==d[t+1],Time[t]+1,1)
  #state transition m
  if ((d[t]==1)&(d[t+1]==2)) {s[t]<-1}
  else if ((d[t]==2)&(d[t+1]==1)) {s[t]<-2}
  else if ((d[t]==1)&(d[t+1]==3)) {s[t]<-3} 
  else if ((d[t]==2)&(d[t+1]==3)) {s[t]<-4}
  else s[t]<-0
  }
  Time<-Time[sit:(K-1)]
  s<-s[sit:(K-1)]


 #chain data
if (any(s!= 0)==TRUE) {#transfer has occurred
    if(last(Time)==1){# Transfer occurred at the last time point
  for(l in 1:(sum(s!= 0))){#sum(s! = 0) denote the number of transitions occurred
    ci<-c(ID=i,y=Time[which(s!= 0)][l],m=s[which(s!= 0)][l],"k"=which(s!= 0)[l],X=x,sigema=1)
    ci<-as.data.frame(t(ci))
    colnames(ci)<-c("ID","y","m","k","X","sigema")
    c<-rbind(c,ci)
  }
    }


    if(last(Time)>1){# No transfer occurred at the last point in time
     for(l in 1:(sum(s!= 0))){
   ci1<-c(ID=i,y=Time[which(s!= 0)][l],m=s[which(s!= 0)][l],"k"=which(s!= 0)[l],X=x,sigema=1)
   ci1<-as.data.frame(t(ci1))
    colnames(ci1)<-c("ID","y","m","k","X","sigema")
   c<-rbind(c,ci1)
     }


    if(last(d)==1|last(d)==2){## The last status is not dead, indicating that there is censoring data
   ci2<-c(ID=i,y=last(Time)-1,m=last(d),"k"=k-sit,X=x,sigema=0)
   ci3<-c(ID=i,y=last(Time)-1,m=last(d)+2,"k"=k-sit,X=x,sigema=0)
   #m=1 in the last time correspond the censoring data of m=1/m=3;m=2 in the last time correspond the censoring data of m=2/m=4 
   ci2<-as.data.frame(t(ci2))
   ci3<-as.data.frame(t(ci3))
    colnames(ci2)<-c("ID","y","m","k","X","sigema")
    colnames(ci3)<-c("ID","y","m","k","X","sigema")
    c<-rbind(c,ci2,ci3)
  }
      if(last(d)==3){
  c<-c
     }
    }
     }#If last(time) is greater than 1 and is not in state 3, then the survival time of the individual in state 1/2 is the censoring data and the survival time is last(time)-1


 if (any(s!= 0)==FALSE) {
  ci<-c(ID=i,y=last(Time)-1,m=last(d),"k"=k-sit,X=x,sigema=0)
  ci<-as.data.frame(t(ci))
    colnames(ci)<-c("ID","y","m","k","X","sigema")
    c<-as.data.frame(rbind(c,ci))
   }

                 return(c)
               }
C_1<-as.data.frame(c_1[which(!c_1$ID==0),])
C_1$y<-ifelse(C_1$y<=56,(C_1$y)/7,(C_1$y)-56+8)
summary(C_1$y)
C[[kk]]<-C_1
}
stopCluster(cl)
dim(C)
write.csv(C,"~/Desktop/C_sample_con.csv")#_con,_var,_norm
~~~~~~~~~~



// 5. BCMC
library(rjags)
install.packages('coda')
library(coda)
library(foreach)
library(iterators)
library(parallel)
library(doParallel)
library(R2jags)
library(coda)
library(lattice)
library(MCMCvis)
# Dimension of vector d is k
a <- 0
d<-int
K<-length(int)
for(j in 2:K){
a[j] <- (d[j-1] + d[j])/2
}
a[j+1] <- d[j] + (d[j] - d[j-1])/2


j<-1
/// 5.1  Load  data
c<-6#c("ID","t","m","j","X","sigema")
m<-4
C_2<-rbind(C[[j]],C[[K+1]])
l<-c(rep(NA,4))
for(m in 1:4){
l[m]<-length(which(C_2$m==m))
}


row<-max(l)
Y<-c(rep(NA, row*c*m))
dim(Y)<-c(row,c,m)
colnames(Y) <-c("ID","t","m","j","X","sigema")
for(m in 1:4){
  len1<-l[m]
 Y[1:len1,,m]<-as.matrix(C_2[which(C_2$m==m),])
}

#"ID","t","m","j","X","sigema"
Y2<-Y[,2,]
Y6<-Y[,6,]
interval<-1

///5.2  Construct H[i,m] and N[i,m]
h<-matrix(0,row,m)
nn<-matrix(0,row,m)
for(m in 1:4){
for(i in 1:l[m]){
h0<- ifelse(Y2[i,m]*interval < a[j],0,1)
aa0<-ifelse(Y2[i,m]*interval > a[j+1],0,1)
h[i,m]<-h0*(min(Y2[i,m]*interval,a[j+1])-a[j])
nn[i,m]<-h0*aa0*delta[i,m]
}
}

/// 5.3 Bayesian Estimation
Y5<-Y[,5,]
lam<-matrix(0,m,K)
beta<-matrix(0,m,K)
lam1<-lam[,j]
beta1<-beta[,j]

model_string <- textConnection("
  model{
# Likelihood Construction
for(m in 1:4){
for(i in 1:l[m]){
nn[i,m]~ dpois(exp(beta1[m]*(Y5[i,m]))*h[i,m]*lam1[m])
}}

  # Prior for lambdas
lamm <- 10000*(0.01) # exp(-a[2]*0.01) = 0.995
for(m in 1:4){
lam1[m] ~ dgamma(lamm,10000)#j=1
}

# Inferences for the HRs and prior on the betas
# relative hazard
for(m in 1:4){
beta1[m] ~ dnorm(0,0.000001)
}# 
}
")
data_list <- list(l=l,Y5=Y5,h=h,nn=nn)
m<-4
inits <- list(beta1=rnorm(m),lam1=rep(0.1,m))
model <- jags.model(model_string,data = data_list, inits=inits, n.chains=2,n.adapt=1000)
#(4)generate 20000 post-burn-in samples
params <- c("beta1")#,"lam","S.pos","S.neg","S.diff") 
sample <- coda.samples(model,variable.names=params,n.iter=20000, progress.bar="none")#
#(5)Summarize the output
sum<-summary(sample)
beta_post0_con<-cbind(mean=sum[["statistics"]][,1],lwr=sum[["quantiles"]][,1],upr=sum[["quantiles"]][,5])

～～～～
#j:2~K


m<-4
f<-rep(0,m)
e<-rep(0,m)
lam<-matrix(0,m,K)
beta<-matrix(0,m,K)

cl <- makeCluster(n.cores-1) 
registerDoParallel(cl)

beta_post1_con<-foreach(j = 2:K,
               .combine = rbind,
              .packages = c("R2jags","coda","lattice","MCMCvis"),
               .errorhandling = "pass") %dopar% {
# 1.data list
lam1<-lam[,j]
beta1<-beta[,j]

C_2<-rbind(C[[j]],C[[K+1]])
l<-c(rep(NA,4))
for(m in 1:4){
l[m]<-length(which(C_2$m==m))
}
row<-max(l)
Y<-c(rep(NA, row*c*m))
dim(Y)<-c(row,c,m)
colnames(Y) <-c("ID","t","m","j","X","sigema")
for(m in 1:4){
  len1<-l[m]
 Y[1:len1,,m]<-as.matrix(C_2[which(C_2$m==m),])
}

m<-4
#"ID","t","m","j","X","sigema"
Y2<-Y[,2,]
Y6<-Y[,6,]
interval<-1

# Construct H[i,m] and N[i,m]
h<-matrix(0,max(l),m)
nn<-matrix(0,max(l),m)
for(m in 1:4){
for(i in 1:l[m]){
h0<- ifelse(Y2[i,m]*interval < a[j],0,1)
aa0<-ifelse(Y2[i,m]*interval > a[j+1],0,1)
h[i,m]<-h0*(min(Y2[i,m]*interval,a[j+1])-a[j])
nn[i,m]<-h0*aa0*delta[i,m]
}
}
a1<-a[j+1]-a[j]


#2.constrcut model
model_string <- textConnection("
  model{
# Likelihood Construction
for(m in 1:4){
for(i in 1:l[m]){
nn[i,m]~ dpois(exp(beta1[m]*(Y1[i,m]))*h[i,m]*lam1[m])
}}

  # Prior for lambdas
lamstar <- 0.05# Select value or set prior for lamstar
w<-0.01
# lamstar ~ dgamma(a,ww) a=0.05*ww ww=0.01
for(m in 1:4){
# prior on baseline hazard bits
f[m] <- w*a1
e[m] <- lamstar*f[m]
lam1[m] ~ dgamma(e[m],f[m])
}

# Inferences for the HRs and prior on the betas
# relative hazard
for(m in 1:4){
beta1[m] ~ dnorm(0,0.000001)
} 
}")

data_list <- list(l=l,Y1=Y1,h=h,nn=nn)
m<-4
inits <- list(beta1=rnorm(m),lam1=rep(0.1,m))
model <- jags.model(model_string,data = data_list, inits=inits, n.chains=2,n.adapt=1000)

#(4)generate 20000 post-burn-in samples
params <- c("beta1")#,"lam","S.pos","S.neg","S.diff") 
#params <- c("HR")
sample <- coda.samples(model,variable.names=params,n.iter=20000, progress.bar="none")

# (5) Summarize the output
sum<-summary(sample)
outcome<-as.data.frame(cbind(mean=sum[["statistics"]][,1],lwr=sum[["quantiles"]][,1],upr=sum[["quantiles"]][,5]))
return(outcome3)
}
stopCluster(cl)

beta_post_1<-as.data.frame(rbind(beta_post0_con,beta_post1_con))
write.csv(beta_post_1,"~/Desktop/beta_bcmc_con.csv")#_con,_var,_norm
~~~~~~~~


// 6. fre-cox
library(readr)
C<- read_csv("~/Desktop/C_sample_con.csv")[,-1]
C0<-c(rep(0,7))
for(kk in 1:(K+1)){
  kk<-1
  J<-c(rep(kk,dim(C[[kk]])[1]))
  C1<-cbind(C[[kk]],J)
  C0<-rbind(C0,C1)
}
C0<-C0[-1,]

m<-4 
HR_Fre<-matrix(0,m,3)
library(survival)
for(m in c(1:4)){
  data0<-C0[which(C0$m==m),]
  data<-list(y=data0$y,group=data0$X,delta=data0$sigema)
  res.cox <- coxph(Surv(y, delta) ~ group, data = data)
  sum<-summary(res.cox)
  HR_Fre[m,]<-cbind(sum$coefficients[2],sum$conf.int[3],sum$conf.int[4])
}

colnames(HR_Fre)<-c("HR","low","upr")
write.csv(HR_Fre,"~/Desktop/HR_fre_con.csv")#_con,_var,_norm
~~~~~~~~


// 7. time-varying cox (contimuous function)
install.packages(c("survival", "survminer"))
library("survival")
library("survminer")
HR_TV<-matrix(0,K,m)
HR_TV_low<-matrix(0,K,m)
HR_TV_upr<-matrix(0,K,m)

for(m in c(1:4)){ 
  data0<-C0[which(C0$m==m),]
  data<-list(y=data0$y,group=data0$X,delta=data0$sigema)
  fit<- coxph(Surv(y, delta) ~ group+tt(group), data = data,tt =function(x,int,...) x * log(int))
  sum<-summary(fit)
 HR_TV[,m]<-exp(sum$coefficients[1,1]+sum$coefficients[2,1]*log(int))
 HR_TV_low[,m]<-exp(log(sum$conf.int[1,3])+log(sum$conf.int[2,3])*log(int))
 HR_TV_upr[,m]<-exp(log(sum$conf.int[1,4])+log(sum$conf.int[2,4])*log(int))
}

HR_TV<-cbind(HR_TV,HR_TV_low,HR_TV_upr)
write.csv(HR_TV,"~/Desktop/HR_TV_con.csv")#_con,_var,_norm
~~~~~~~~


// 8.regularize and fit Estimated value<p>
/// 8.1 Filter,Normalize,Average 
beta_post_1<- read_csv("~/Desktop/beta_bcmc_con.csv")
HR_cox <- read_csv("~/Desktop/HR_fre_con.csv")[,-1]
HR_TV <- read_csv("~/Desktop/HR_TV_con.csv")[,-1]
beta <- read_csv("~/Desktop/beta_true_con.csv")[,-1]
beta_post_11<-c(beta_post_1$mean,beta_post_1$upr)
x<-c(0:(length(int)*2))
beta_post<-as.data.frame(x)
be<-c(0)

for(m in 1:4){
  for(t in 1:(length(int)*2)){
  row<-m+4*(t-1)
  be<-c(be,beta_post_11[row])#mean
  }
  beta_post<-cbind(beta_post,be)
  be<-c(0)
}
beta_post<-beta_post[-1,]
colnames(beta_post)<-c("x","y1","y2","y3","y4")
summary(beta_post)
dim(beta_post)
beta_post$y1f<-beta_post$y1
beta_post$y2f<-beta_post$y2
beta_post$y3f<-beta_post$y3
beta_post$y4f<-beta_post$y4

fan<-cbind(1:length(int),(1:length(int))+length(int))
for(m in 1:4){
ci<-beta_post[fan[,2],m+1]-beta_post[fan[,1],m+1]
ci[which(ci>3)]<-3
beta_post[fan[,2],m+5]<-ci
}
summary(beta_post[fan[,2],])

#Removal of extremes
for(m in 1:4){
  up<-quantile(beta_post[fan[,1],m+1], 0.975)
  lw<-quantile(beta_post[fan[,1],m+1], 0.025)
for(t in fan[-1,1]){
  beta_post[t,m+5]<-ifelse(beta_post[t,m+1]<=up&beta_post[t,m+1]>=lw,beta_post[t,m+1],beta_post[t-1,m+5])
}
  }

#normalization
stan1<-HR_cox[4,1]
redu<-abs(log(stan1)/mean(beta_post$y4f[fan[,1]]))
for(m in 1:4){
  beta_post[fan[,1],m+5]<-beta_post[fan[,1],m+5]*redu
}

#average
for(l in 1:2){  
for(m in 1:4){
for(t in fan[,l]){
  beta_post[t,m+9]<-(mean(beta_post[(max(min(fan[,l]),(t-5))):(min(max(fan[,l]),(t+5))),m+5]/2))
}
}
}

plot(int, beta_post$V10[fan[,1]], type="l", col="steelblue2" , xlab="Weeks",ylab="beta",ylim=c(-4,4),main="Time-varying beta (After filtering)",bty="l",lwd=1)#range(beta_post$V10,na.rm=TRUE)
lines(int, beta_post$V11[fan[,1]], type="l", col="purple",lwd=1)
lines(int, beta_post$V12[fan[,1]], type="l", col="palegreen3",lwd=1)
lines(int, beta_post$V13[fan[,1]], type="l", col="gold1",lwd=1)
lines(int, rep(0,length(int)), lty=2, col="black",lwd=1)
legend("topright", legend=c("PFS-PD", "PD-PFS", "PFS-D", "PD-D","beta=0"), col=c("steelblue1", "purple", "palegreen3", "gold1","black"), lty=c(1,1,1,1,2), cex=0.8,lwd=1.5,bty="n")

beta_post<-beta_post[,10:13]
write.csv(beta_post,"~/Desktop/beta_stan_con.csv")
~~~~~~~~


// 8.2 weibull fit and 95%CI
#weibull fit
library(readr)
beta_post <-read_csv("~/Desktop/beta_stan_con.csv")[,-1]
staus<-c("var")#con,var,norm
bcmc_wei<-list()
length(int)
fan<-cbind(1:length(int),(1:length(int))+length(int))


library (MASS)
for(m in 1:4){
fit_num<-c((1:8)*7,57:length(int))
y1<-beta_post[fan[,1],m]
y0<-exp(y1)
y_fit<-data.frame(matrix(0,k,3))
y<-y0[fit_num]
 if ((m==1)|(m==3)|(m==4)) {y[which(y>1)]<-1}
   if (m==2) {y[which(y<1)]<-1}
y<-y-1
inter<-1
redu<-sum(y)*inter/2
y<-y/redu
sum(y*inter)#=1
X<-sample(1:(k)-0.5,10000,prob=y,replace = TRUE)
fit<-fitdistr(X, "Weibull")
shape<-fit[["estimate"]][1]
scale<-fit[["estimate"]][2]
t<-c(1:k)
fitting<-dweibull(t, shape = shape, scale = scale)
y_fit[,1]<-fitting*(redu)+1
if((m==1)){plot(t, y_fit[,1], type="l", col="steelblue2", ylim=c(0,4), xlab="Week", ylab="beta", main="Time-varying beta")}
lines(t,rep(0.5,260))
if((m==2)|(m==3)|(m==4)){lines(t, y_fit[,1], type="l", col="steelblue2", ylim=c(0,4), xlab="Week", ylab="beta", main="Time-varying beta")}
bcmc_wei[[m]]<-y_fit
}

#95%ci
library(foreach)
library(iterators)
library(parallel)
library(doParallel)
z<-1.96
n0<-2500
staus<-c("con")
staus<-c("var")
staus<-c("norm")
dat_all<-list()
for(m in 1:4){
y_95<-matrix(NA,nrow=n0,ncol=length(int))
mean<-exp(beta_post[fan[,1],m])
upr<-exp(beta_post[fan[,1],m]+beta_post[fan[,2],m])
sd0<-(upr-mean)/z*((n0)^(1/2))
for(col in 1:length(int)){
y_95[,col]<-rnorm(n0,mean=as.numeric(mean[col]),sd=as.numeric(sd0[col]))
}
fitting<-matrix(NA,nrow=n0,ncol=k)
  cl <- makeCluster(n.cores-1) 
registerDoParallel(cl)
fitting<-foreach(nn = 1:n0,
               .combine = rbind,
               .packages = c("MASS"),
               .errorhandling = "pass") %dopar% {
                 y<-y_95[nn,fit_num]
   base<-1+mean(y)-mean(as.vector(mean[1])[[1]])
  if ((m==1)|(m==3)|(m==4)) {y[which(y>base)]<-base}
 if (m==2) {y[which(y<base)]<-base}
y<-y-base
inter<-1
redu<-sum(y)*inter/1
y<-y/redu
sum(y*inter)#=1
length(y)
X<-sample(1:(k),10000,prob=y,replace = TRUE)
fit<-fitdistr(X, "Weibull")
shape<-fit[["estimate"]][1]
scale<-fit[["estimate"]][2]
t<-c(1:k)
weibull<-dweibull(t, shape = shape, scale = scale)


#plot(weibull)
#lines(weibull)
weibull<-weibull*(redu)+base
return(weibull)
}
stopCluster(cl)
y_upr<-c()
y_lwr<-c()
  for(col in 1:(k)){
  fitt<-as.numeric(unlist((fitting[,col])))
y_upr[col]<-quantile(fitt, 0.975,na.rm=TRUE)
y_lwr[col]<-quantile(fitt, 0.025,na.rm=TRUE)
  }
stan<-((bcmc_wei[[m]][,1])-1)/((max(y_upr)+min(y_lwr))/2-1)
base_1<-mean(1-bcmc_wei[[m]][,1])
y_upr_1<-(y_upr-1)*stan+1+base_1
y_lwr_1<-(y_lwr-1)*stan+1-base_1
t<-1:(k)
plot(t, bcmc_wei[[m]][,1], type="l", col="steelblue2", ylim=c(0,3), xlab="Week", ylab="beta", main="Time-varying beta")
lines(t,y_upr_1,type="l")
lines(t,y_lwr_1,type="l")
lines(t,rep(0.5,k),type="l")
bcmc_wei[[m]][,2]<-y_upr_1
bcmc_wei[[m]][,3]<-y_lwr_1
min(y_lwr)
colnames(bcmc_wei[[m]])<-c("bcmc","bcmc_lwr","bcmc_upr")
y_cox<-cbind(rep(as.numeric(HR_cox[m,1]),length(t)),rep(as.numeric(HR_cox[m,2]),length(t)),rep(as.numeric(HR_cox[m,3]),length(t)))
colnames(y_cox)<-c("cox","cox_lwr","cox_upr")
y_tv<-cbind(HR_TV[,m],HR_TV[,m+4],HR_TV[,m+8])[c((1:8)*7,57:308),]
colnames(y_tv)<-c("tv","tv_lwr","tv_upr")
y_true<-t(exp(beta[m,]))
x<- data.frame(x = t)
dat_all[[m]]<-cbind(x,bcmc_wei[[m]],y_cox,y_tv,y_true)
}
dat_weibull<-dat_all
~~~~~~~~


// 8.3 linear fit and 95%ci
#linear fit
library(readr)
beta_post <- read_csv("~/Desktop/beta_stan_con.csv")[,-1]
library (MASS)
bcmc_lin<-list()
y_fit<-data.frame(matrix(0,length(int),3))
for(m in 1:4){
y1<-beta_post[fan[,1],m]
y0<-exp(y1)
dat_fit<-as.data.frame(cbind(y0,int))
colnames(dat_fit)<-c("y0","int")
fit<-lm(y0~int,data=dat_fit)
y_fit[,1]<-fitted(fit)
if((m==1)){plot(int, y_fit[,1], type="l", col="steelblue2", ylim=c(0,4), xlab="Week", ylab="beta", main="Time-varying beta")}
lines(t,rep(0.5,260))
if((m==2)|(m==3)|(m==4)){lines(int, y_fit[,1], type="l", col="steelblue2", ylim=c(0,4), xlab="Week", ylab="beta", main="Time-varying beta")}
bcmc_lin[[m]]<-y_fit[fit_num,]
}

z<-1.96
n0<-2500
dat_all<-list()
for(m in 1:4){
y_95<-matrix(NA,nrow=n0,ncol=length(int))
mean<-exp(beta_post[fan[,1],m])
upr<-exp(beta_post[fan[,1],m]+beta_post[fan[,2],m])
sd0<-(upr-mean)/z*((n0)^(1/2))
for(col in 1:length(int)){
y_95[,col]<-rnorm(n0,mean=as.numeric(mean[col]),sd=as.numeric(sd0[col]))
}
fitting<-matrix(NA,nrow=n0,ncol=k)
  cl <- makeCluster(n.cores-1) 
registerDoParallel(cl)
fitting<-foreach(nn = 1:n0,
               .combine = rbind,
               .packages = c("MASS"),
               .errorhandling = "pass") %dopar% {
                 y1<-y_95[nn,]
y0<-y1
dat_fit<-as.data.frame(cbind(y0,int))
colnames(dat_fit)<-c("y0","int")
fit<-lm(y0~int,data=dat_fit)
fitted<-fitted(fit)[fit_num]
return(fitted)
}
stopCluster(cl)
  for(col in 1:(k)){
  fitt<-as.numeric(unlist((fitting[,col])))
y_upr[col]<-quantile(fitt, 0.975,na.rm=TRUE)
y_lwr[col]<-quantile(fitt, 0.025,na.rm=TRUE)
  }
base_1<-max(bcmc_lin[[m]][,1])
stan_1<-(bcmc_lin[[m]][,1]-base_1)/((y_upr)+(y_lwr)/2-base_1)
y_upr_1<-(y_upr-base_1)*stan_1+base_1
y_lwr_1<-bcmc_lin[[m]][,1]*2-y_upr_1


#m<-1,0.2
t<-1:(k)
plot(t, bcmc_lin[[m]][,1], type="l", col="steelblue2", ylim=c(0,4), xlab="Week", ylab="beta", main="Time-varying beta")
lines(t,y_upr_1,type="l")
lines(t,y_lwr_1,type="l")
lines(t,rep(1,k),type="l")
bcmc_lin[[m]][,2]<-y_upr_1
bcmc_lin[[m]][,3]<-y_lwr_1
colnames(bcmc_lin[[m]])<-c("bcmc","bcmc_lwr","bcmc_upr")
y_cox<-cbind(rep(as.numeric(HR_cox[m,1]),length(t)),rep(as.numeric(HR_cox[m,2]),length(t)),rep(as.numeric(HR_cox[m,3]),length(t)))
colnames(y_cox)<-c("cox","cox_lwr","cox_upr")
y_tv<-cbind(HR_TV[,m],HR_TV[,m+4],HR_TV[,m+8])[fit_num,]
colnames(y_tv)<-c("tv","tv_lwr","tv_upr")
y_true<-t(exp(beta[m,]))
x<- data.frame(x = t)
dat_all[[m]]<-cbind(x,bcmc_lin[[m]],y_cox,y_tv,y_true)
}     
dat_linear<-dat_all
~~~~~~~~


// 8.4 select better fitting model<p>
for(m in 1:4){
dat_lin<-dat_linear[[m]]
dat_wei<-dat_weibull[[m]]
origin<-beta_post[fan[,1],m][fit_num,]
mse_1<-(dat_lin$bcmc-exp(origin))^2
mse_2<-(dat_wei$bcmc-exp(origin))^2
print(mean(mse_1[,1]))
print(mean(mse_2[,1]))
dat_all[[m]][,2:4]<-ifelse(mse_1<mse_2,dat_lin[,2:4],dat_wei[,2:4])
}
write.csv(dat_all,"~/Desktop/HR_ALL_con.csv")
~~~~~~~~


// 9. Table_1<p>
<!--begin.rcode
library(readr)
dat_con<- read_csv("~/Desktop/HR_ALL_con.csv")[,-1]
dat_var<- read_csv("~/Desktop/HR_ALL_var.csv")[,-1]
dat_norm<- read_csv("~/Desktop/HR_ALL_norm.csv")[,-1]
mae<-0
mse<-0
mape<-0
mae_5<-0
mse_5<-0
dat<-as.data.frame(0)
for(m in 1:4){
  dat<-dat_draw[,c((m-1)*11+2,(m-1)*11+5,(m-1)*11+8,(m-1)*11+11)]
  colnames(dat)<-c("bcmc","cox","tv","true")
  a<-mean(abs(dat$true-dat$cox))
  b<-mean(abs(dat$true-dat$tv))
  c<-mean(abs(dat$true-dat$bcmc),na.rm = TRUE)
  mae<-c(mae,a,b,c)
  d<-mean((dat$true-dat$cox)^2)
  e<-mean((dat$true-dat$tv)^2)
  f<-mean((dat$true-dat$bcmc)^2,na.rm = TRUE)
  mse<-c(mse,d,e,f)
  g<-paste0(mean(abs((dat$true-dat$cox)/dat$true))*100,"%")
  h<-paste0(mean(abs((dat$true-dat$tv)/dat$true))*100,"%")
  j<-paste0(mean(abs((dat$true-dat$bcmc)/dat$true),na.rm = TRUE)*100,"%")
  mape<-c(mape,g,h,j)
  #k<-paste0("(",round(t.test(abs(dat$true-dat$cox))$conf.int[1],2),",",round(t.test(abs(dat$true-dat$cox))$conf.int[2],2),")")
  k<-0#for constant
  l<-paste0("(",round(t.test(abs(dat$true-dat$tv))$conf.int[1],2),",",round(t.test(abs(dat$true-dat$tv))$conf.int[2],2),")")
  m<-paste0("(",round(t.test(abs(dat$true-dat$bcmc))$conf.int[1],2),",",round(t.test(abs(dat$true-dat$bcmc))$conf.int[2],2),")")
  mae_5<-c(mae_5,k,l,m)
  #n<-paste0("(",round(t.test((dat$true-dat$cox)^2)$conf.int[1],2),",",round(t.test((dat$true-dat$cox)^2)$conf.int[2],2),")")
   n<-0#for constant
  o<-paste0("(",round(t.test((dat$true-dat$tv)^2)$conf.int[1],2),",",round(t.test((dat$true-dat$tv)^2)$conf.int[2],2),")")
  p<-paste0("(",round(t.test((dat$true-dat$bcmc)^2)$conf.int[1],2),",",round(t.test((dat$true-dat$bcmc)^2)$conf.int[2],2),")")
 mse_5<-c(mse_5,n,o,p)
  }

rmse<-sqrt(mse)
out_con<-cbind(mae,mae_5,mse,mse_5,rmse,mape)[-1,]
out_var<-cbind(mae,mae_5,mse,mse_5,rmse,mape)[-1,]
out_norm<-cbind(mae,mae_5,mse,mse_5,rmse,mape)[-1,]

write.csv(out_con,"~/Desktop/table1_con_z.csv")
write.csv(out_var,"~/Desktop/table1_var_z.csv")
write.csv(out_norm,"~/Desktop/table1_norm_z.csv")
~~~~~~~~


// 10. Table_2<p>
t<-c(1:(k))
dat_norm<-dat_draw
a<-t[which.min(dat_norm$bcmc...3)]
b<-t[which.max(dat_norm$bcmc...14)]
c<-t[which.min(dat_norm$bcmc...25)]
d<-t[which.min(dat_norm$bcmc...36)]

top<-c(k/2,a,b,c,d)
top
os_norm<-c(0)
for(k in top){
  p_list_tr_var <- p_list
  p_list_tr_var[,,(1:k)]<-p_list_tr[,,(1:k)]
data_var <- as.data.frame(0, nrow = n, ncol = 260+1)
for(i in 1:n){
  current_state <- rep(1:2,each=n/2)[i]
  data_var[i,1] <- c(current_state)  # Store sample sequences
  for(t in 1:260){
    next_state <- sample(1:states, 1, prob = p_list_tr_var[current_state,,t])
  data_var[i,t+1] <- c(as.numeric(next_state))
  current_state<-next_state
  }
}
h<-c(1:k)
os<-apply(data_var,1,function(x){h[which(x==3)[1]]})
os_norm<-cbind(os_norm,os)
}
os_norm<-os_norm[,-1]
summary(os_norm)
OS_NORM_2<-c(0)
for(c in 1:5){
 mean<-mean(os_norm[,c],na.rm =TRUE)
 mean_low<-t.test(os_norm[,c])$conf.int[1]
 mean_up<-t.test(os_norm[,c])$conf.int[2]
 os<-paste0(round(mean/4,2),"(",round(mean_low/4,2),"~",round(mean_up/4,2),")")
 OS_NORM_2<-cbind(OS_NORM_2,c(mean,mean_low,mean_up,os))
}
colnames(OS_NORM_2)
OS_NORM_2<-rbind(top,OS_NORM_2[,-1])
write.csv(OS_NORM_2,"~/Desktop/table2_norm_z.csv")
~~~~~~~~


// 11. constant freeplot<p>
library(readr)
dat_con<- read_csv("~/Desktop/HR_ALL_con.csv")[,-1]

esti<-c()
for(m in 1:4){
  dat<-dat_con[,c(((m-1)*11+2),((m-1)*11+5):((m-1)*11+8),((m-1)*11+11))]
  colnames(dat)<-c("bcmc","cox","cox_lwr","cox_upr","tv","true")
  a0<-dat$true[1]
  a<-c(dat$cox[1],dat$cox_lwr[1],dat$cox_upr[1])
  b<-c(mean(dat$tv),quantile(dat$tv, 0.025),quantile(dat$tv, 0.975))
  c<-c(mean(dat$bcmc),quantile(dat$bcmc, 0.025),quantile(dat$bcmc, 0.975))
  esti<-rbind(esti,a0,a,b,c)
}
 esti<-as.data.frame(esti)
esti$ES_95<-paste0(round(esti[,1],2)," (",round(esti[,2],2),", ",round(esti[,3],2),")")

write.csv(esti,"~/Desktop/table2_con_z.csv")
~~~~~~~~


// 12. TVC-Cox(B splines)<p>
dat_all<-list()
library(readr)
dat_draw <- read_csv("~/Desktop/HR_ALL_norm.csv")[,-1]
for(m in 1:4){
  dat_all[[m]]<-dat_draw[,((m-1)*11+1):((m-1)*11+14)]
  colnames(dat_all[[m]])<-c("x","bcmc","bcmc_lwr","bcmc_upr","cox","cox_lwr","cox_upr","tv","tv_lwr","tv_upr","y_true")
}

library(survival)
library(casebase)
library(splines)
  m<-1
  m<-2
  m<-3
  m<-4
  C3<-C0[which(C0$m==m),]
  data<-data.frame(y=C3$y,group=C3$X,delta=C3$sigema,tp=C3$J)
fit[[m]]<-fitSmoothHazard(delta~group*ns(tp,df=3),
                    data=data,time="y")
dat_rcs<-list()
newtime=c(1:260)
newdata1=data.frame(group=factor("1",levels=c("1","0")),tp=newtime)
for(m in 1:4){
p1<-plot(fit[[m]],newdata=newdata1,var="group",increment=1,xvar="tp",type="hr",ci=T)
rcs<-data.frame(TVC=p1$hazard_ratio,TVC_lwr=p1$lowerbound,TVC_upr=p1$upperbound)
dat_rcs[[m]]<-cbind(dat_all[[m]],rcs)
}
write.csv(dat_rcs,"~/Desktop/HR_TVC_ALL_norm.csv")
~~~~~~~~


// 13. the time chain data of overall survival pfs/pd-d in realworld analysis<p>
cl <- makeCluster(8-1) 
registerDoParallel(cl)
C_11<-list()
for(kk in 1:(K+1)){#(K+1)
  x<-ifelse(kk<=K,1,0)
data<-data_tran[[kk]]
c_1<-foreach(i = 1:n,
               .combine = rbind,
             .packages = c("dplyr"),
               .errorhandling = "pass") %dopar% {
                 c<-c(rep(0, 6))
                 Time<-c(rep(1, K))
                 s<-c(rep(0, K))
  d<-data[i,]
  sit<-min(which(is.na(d)==FALSE))#if have NA
for(t in sit:(K-1)){
  #survival time t
  Time[t+1]<-ifelse(d[t]==d[t+1],Time[t]+1,1)
  #state transition m
  if ((d[t]==1)&(d[t+1]==2)) {s[t]<-1}
  else if ((d[t]==2)&(d[t+1]==1)) {s[t]<-2}
  else if ((d[t]==1)&(d[t+1]==3)) {s[t]<-3} 
  else if ((d[t]==2)&(d[t+1]==3)) {s[t]<-4}
  else s[t]<-0
  }
  Time<-Time[sit:(K-1)]
  s<-s[sit:(K-1)]


 #chain data
if (any(s!= 0)==TRUE) {#transfer has occurred
    if(last(Time)==1){# Transfer occurred at the last time point
  for(l in 1:(sum(s!= 0))){#sum(s! = 0) denote the number of transitions occurred
    ci<-c(ID=i,y=Time[which(s!= 0)][l],m=s[which(s!= 0)][l],"k"=which(s!= 0)[l],X=x,sigema=1)
    ci<-as.data.frame(t(ci))
    colnames(ci)<-c("ID","y","m","k","X","sigema")
    c<-rbind(c,ci)
  }
    }
    if(last(Time)>1){# No transfer occurred at the last point in time
     for(l in 1:(sum(s!= 0))){
   ci1<-c(ID=i,y=Time[which(s!= 0)][l],m=s[which(s!= 0)][l],"k"=which(s!= 0)[l],X=x,sigema=1)
   ci1<-as.data.frame(t(ci1))
    colnames(ci1)<-c("ID","y","m","k","X","sigema")
   c<-rbind(c,ci1)
     }


    if(last(d)==1|last(d)==2){## The last status is not dead, indicating that there is censoring data
   ci2<-c(ID=i,y=last(Time)-1,m=last(d),"k"=k-sit,X=x,sigema=0)
   ci3<-c(ID=i,y=last(Time)-1,m=last(d)+2,"k"=k-sit,X=x,sigema=0)
   #m=1 in the last time correspond the censoring data of m=1/m=3;m=2 in the last time correspond the censoring data of m=2/m=4 
   ci2<-as.data.frame(t(ci2))
   ci3<-as.data.frame(t(ci3))
    colnames(ci2)<-c("ID","y","m","k","X","sigema")
    colnames(ci3)<-c("ID","y","m","k","X","sigema")
    c<-rbind(c,ci2,ci3)
  }
      if(last(d)==3){
  c<-c
     }
    }
     }#If last(time) is greater than 1 and is not in state 3, then the survival time of the individual in state 1/2 is the censoring data and the survival time is last(time)-1
 

if (any(s!= 0)==FALSE) {
  ci<-c(ID=i,y=last(Time)-1,m=last(d),"k"=k-sit,X=x,sigema=0)
  ci<-as.data.frame(t(ci))
    colnames(ci)<-c("ID","y","m","k","X","sigema")
    c<-as.data.frame(rbind(c,ci))
   }

                 return(c)
               }
C_1<-as.data.frame(c_1[which(!c_1$ID==0),])
C_1$y<-ifelse(C_1$y<=56,(C_1$y)/7,(C_1$y)-56+8)
summary(C_1$y)

# m=1 means pfs-pd
C_11[[kk]]<-C_1[which(C_1$m==1),]
}
stopCluster(cl)


#m=2 means overall survival of pfs/pd-d，including pfs-pd-d，pfs-d，pd-d，pd-pfs-d
cl <- makeCluster(8-1) 
registerDoParallel(cl)
C_22<-list()
for(kk in 1:(K+1)){#(K+1)
  x<-ifelse(kk<=K,1,0)
data<-data_tran[[kk]]
c_2<-foreach(i = 1:num,
               .combine = rbind,
             .packages = c("dplyr"),
               .errorhandling = "pass") %dopar% {
                 ci<-c(rep(NA, 6))
                 Time<-c(rep(1, k))
                 s<-c(rep(0, k))
                 d<-dat_flw[i,]
                 x<-dat_x[i,]
                 sit<-min(which(is.na(d)==FALSE))
 for(t in sit:(k-1)){
  Time[t+1]<-ifelse(d[t]==d[t+1],Time[t]+1,1)
 }
  Time<-Time[sit:k]
  x<-x[sit:k]              
 if(last(d)==1|last(d)==2){
  ci<-c(i,k-sit,2,k-sit,last(x),0)
 }
  if(last(d)==3){ 
   if(d[sit]==1|d[sit]==2){
ci<-c(i,min(which(d==3))-sit,2,min(which(d==3))-sit,as.numeric(x[min(which(d==3))-sit]),1)
   }
   if(d[sit]==3){ 
   ci<-NA  
   }
  }
  return(ci)
               }

C_2<-as.data.frame(c_2[which(!c_2$ID==0),])
C_2$y<-ifelse(C_2$y<=56,(C_2$y)/7,(C_2$y)-56+8)
summary(C_2$y)
C_22[[kk]]<-C_2
}
stopCluster(cl)


C<-list()
for(kk in 1:(K+1)){
  C[[kk]]<-rbind(C_11[[kk]],C_22[[kk]])
}
write.csv(C,"~/Desktop/realworld/C_sample_m2.csv")
#include the chain data of 2 transition paths:pfs-pd,pfs/pd-d(overall survival)

</body>
